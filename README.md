# âœˆï¸ Global Flight Tracking Data Pipeline: Real-Time Lakehouse Architecture

![Power BI Dashboard](images/dashboard.png)


## ğŸ“Œ DescripciÃ³n del Proyecto
Este proyecto es una arquitectura de datos End-to-End diseÃ±ada para ingerir, procesar y visualizar el trÃ¡fico aÃ©reo mundial en tiempo real. Utilizando los principios de la **Arquitectura MedallÃ³n** (Data Lakehouse), el sistema extrae datos de vuelos en vivo, los amortigua mediante un sistema de mensajerÃ­a (Streaming), los procesa y limpia de forma distribuida, y finalmente los sirve para la toma de decisiones empresariales.

Durante las pruebas de estrÃ©s, este pipeline demostrÃ³ la capacidad de procesar **mÃ¡s de 500,000 registros** de vuelos globales en una sola ejecuciÃ³n sin saturaciÃ³n de memoria, garantizando alta disponibilidad y resiliencia.

## ğŸ› ï¸ Stack TecnolÃ³gico
* **IngestiÃ³n & APIs:** Python (`requests`), OpenSky Network API.
* **Streaming & Message Broker:** Redpanda (Alternativa moderna a Apache Kafka en C++).
* **Procesamiento Big Data:** Apache Spark (PySpark).
* **Almacenamiento (Data Lake):** Sistema de archivos local (Formato Parquet).
* **Base de Datos Relacional (Serving Layer):** PostgreSQL.
* **OrquestaciÃ³n de Contenedores:** Docker & Docker Compose.
* **VisualizaciÃ³n & BI:** Power BI.

## ğŸ—ï¸ Arquitectura de Datos (MedallÃ³n)
El flujo de datos sigue el estÃ¡ndar de la industria para garantizar la calidad del dato:

1. **ExtracciÃ³n (Productor):** Un script de Python consulta la API en tiempo real y envÃ­a los datos crudos al clÃºster de Redpanda.
2. **IngestiÃ³n (Consumidor):** Los mensajes en streaming son consumidos y almacenados en el Data Lake.
3. **Capa Bronze (Raw):** Datos crudos guardados en formato Parquet, conservando el historial completo sin alteraciones.
4. **Capa Silver (Cleansed):** PySpark limpia los datos (eliminaciÃ³n de nulos, descarte de aviones en tierra, correcciÃ³n de anomalÃ­as de sensores).
5. **Capa Gold (Business/Aggregated):** PySpark agrupa y resume los datos limpios para responder preguntas de negocio especÃ­ficas.
6. **Serving Layer:** Los datos procesados se inyectan en PostgreSQL para alimentar el Dashboard interactivo.

## ğŸ“‚ Estructura del Repositorio

    flight_tracking_lakehouse/
    â”‚
    â”œâ”€â”€ data/                       # Data Lake local
    â”‚   â”œâ”€â”€ bronze/                 # Datos crudos en formato Parquet
    â”‚   â”œâ”€â”€ checkpoints/            # GestiÃ³n de estado para Spark Streaming
    â”‚   â”œâ”€â”€ silver/                 # Datos limpios, filtrados y sin anomalÃ­as
    â”‚   â””â”€â”€ gold/                   # Datos agregados y optimizados para BI
    â”‚
    â”œâ”€â”€ hadoop/bin/                 # Dependencias nativas (winutils) para ejecutar Spark en Windows
    â”‚
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ ingestion/
    â”‚   â”‚   â””â”€â”€ fetch_flights.py    # Productor: Extrae de la API y publica en Redpanda
    â”‚   â”‚
    â”‚   â””â”€â”€ processing/
    â”‚       â”œâ”€â”€ stream_processor.py # Consumidor: Lee de Redpanda y escribe en Bronze
    â”‚       â”œâ”€â”€ bronze_to_silver.py # PySpark Batch: Limpieza y estandarizaciÃ³n
    â”‚       â”œâ”€â”€ silver_to_gold.py   # PySpark Batch: AgrupaciÃ³n y reglas de negocio
    â”‚       â”œâ”€â”€ gold_to_postgres.py # InyecciÃ³n de capa Gold a PostgreSQL
    â”‚       â”œâ”€â”€ inspect_bronze.py   # Script de soporte: AnÃ¡lisis exploratorio
    â”‚       â””â”€â”€ query_silver.py     # Script de soporte: ValidaciÃ³n de calidad de datos
    â”‚
    â”œâ”€â”€ venv/                       # Entorno virtual aislado de Python
    â”œâ”€â”€ .env                        # Variables de entorno y credenciales (Ignorado en Git)
    â”œâ”€â”€ .gitignore                  # Reglas de exclusiÃ³n para el repositorio
    â”œâ”€â”€ docker-compose.yml          # Infraestructura como CÃ³digo (Redpanda, PostgreSQL)
    â”œâ”€â”€ README.md                   # DocumentaciÃ³n principal del proyecto
    â”œâ”€â”€ requirements.txt            # Listado de dependencias y librerÃ­as de Python
    â””â”€â”€ setup_hadoop.py             # Script de automatizaciÃ³n de entorno

## ğŸš€ Instrucciones de EjecuciÃ³n

### 1. Levantar la Infraestructura
En una terminal, Inicia los servicios de Redpanda y PostgreSQL mediante Docker:
docker-compose up -d

### 2. Iniciar el Flujo de Streaming
Ejecuta el productor para extraer los datos del mundo entero (se ejecutarÃ¡ en bucle cada 30 segundos):
python src/ingestion/fetch_flights.py

En una segunda terminal, ejecuta el consumidor para guardar el streaming en la Capa Bronze:
python src/processing/stream_processor.py

### 3. Procesamiento Batch con PySpark
Una vez recolectados los datos, ejecuta las transformaciones en orden:
python src/processing/bronze_to_silver.py
python src/processing/silver_to_gold.py

### 4. Servir a la Base de Datos
Carga la tabla final a PostgreSQL para ser consumida:
python src/processing/gold_to_postgres.py


## ğŸ“Š Insights y Resultados
Limpieza automÃ¡tica de datos: Se implementÃ³ lÃ³gica en PySpark capaz de filtrar anomalÃ­as, aviones estacionados y errores de transpondedor, asegurando la calidad de los datos para anÃ¡lisis.

Desacoplamiento efectivo: El uso de Redpanda previno cuellos de botella durante extracciones masivas, soportando la ingesta continua sin pÃ©rdida de mensajes.

AnÃ¡lisis de Vuelo: El modelo de datos final en Power BI permite analizar la correlaciÃ³n directa entre altitud y velocidad (fÃ­sica de vuelo) mediante el uso de identificadores Ãºnicos (id_vuelo).
